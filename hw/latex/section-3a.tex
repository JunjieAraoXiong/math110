% ── Section 3A ──

\exerciseheader{3A}{1}
\begin{exercise}{1}
  Suppose $b, c \in \R$. Define $T\colon \R^3 \to \R^2$ by
  \[
    T(x, y, z) = (2x - 4y + 3z + b,\, 6x + cxyz).
  \]
  Show that $T$ is linear if and only if $b = c = 0$.
\end{exercise}
\begin{solution}
  First suppose $b = c = 0$. Then
  \[
    T(x, y, z) = (2x - 4y + 3z,\, 6x),
  \]
  which easily implies that $T$ is linear.

  Conversely, now suppose that $T$ is linear. Note that
  \[
    T(0, 0, 0) = (b, 0).
  \]
  Now 3.10 implies that $b = 0$.

  Note that
  \[
    T(1, 1, 1) = (1, 6 + c) \quad \text{and} \quad T(2, 2, 2) = (2, 12 + 8c).
  \]
  The equation $T(2, 2, 2) = 2T(1, 1, 1)$ implies that $12 + 8c = 12 + 2c$, which implies that $c = 0$.
\end{solution}

\exerciseheader{3A}{2}
\begin{exercise}{2}
  Suppose $b, c \in \R$. Define $T\colon \mathcal{P}(\R) \to \R^2$ by
  \[
    Tp = \bigl(3p(4) + 5p'(6) + bp(1)p(2),\, \int_{-1}^{2} x^3 p(x)\,dx + c\sin p(0)\bigr).
  \]
  Show that $T$ is linear if and only if $b = c = 0$.
\end{exercise}
\begin{solution}
  First suppose $b = c = 0$. Then
  \[
    Tp = \bigl(3p(4) + 5p'(6),\, \int_{-1}^{2} x^3 p(x)\,dx\bigr),
  \]
  which easily implies that $T$ is linear.

  Conversely, now suppose that $T$ is linear. Note that
  \[
    T1 = \bigl(3 + b,\, \tfrac{15}{4} + c\sin 1\bigr) \quad \text{and} \quad T2 = \bigl(6 + 4b,\, \tfrac{15}{2} + c\sin 2\bigr)
  \]
  The equation $T2 = 2T1$ implies that $6 + 4b = 6 + 2b$ and $\tfrac{15}{2} + c\sin 2 = \tfrac{15}{2} + 2c\sin 1$, which implies that $b = 0$ and $c = 0$.
\end{solution}

\exerciseheader{3A}{3}
\begin{exercise}{3}
  Suppose that $T \in \mathcal{L}(\F^n, \F^m)$. Show that there exist scalars $A_{j,k} \in \F$ for $j = 1, \dots, m$ and $k = 1, \dots, n$ such that
  \[
    T(x_1, \dots, x_n) = (A_{1,1}x_1 + \cdots + A_{1,n}\,x_n,\, \dots,\, A_{m,1}x_1 + \cdots + A_{m,n}\,x_n)
  \]
  for every $(x_1, \dots, x_n) \in \F^n$.

  \textit{This exercise shows that the linear map $T$ has the form promised in the second to last item of Example~3.3.}
\end{exercise}
\begin{solution}
  Let $e_1, \dots, e_n$ denote the standard basis of $\F^n$. Furthermore, let $f_1, \dots, f_m$ denote the standard basis of $\F^m$. Then for $k = 1, \dots, n$, there are numbers $A_{j,k}$ such that
  \[
    Te_k = \sum_{j=1}^{m} A_{j,k} f_j.
  \]
  Thus
  \begin{align*}
    T(x_1, \dots, x_n) &= x_1 Te_1 + \cdots + x_n Te_n \\
                        &= x_1 \sum_{j=1}^{m} A_{j,1} f_j + \cdots + x_n \sum_{j=1}^{m} A_{j,n} f_j \\
                        &= \sum_{j=1}^{m} (A_{j,1}x_1 + \cdots + A_{j,n}x_n) f_j.
  \end{align*}
  Thus the $j^{\text{th}}$-coordinate of $T(x_1, \dots, x_n)$ is $A_{j,1}x_1 + \cdots + A_{j,n}x_n$, as desired.
\end{solution}

\exerciseheader{3A}{4}
\begin{exercise}{4}
  Suppose $T \in \mathcal{L}(V, W)$ and $v_1, \dots, v_m$ is a list of vectors in $V$ such that $Tv_1, \dots, Tv_m$ is a linearly independent list in $W$. Prove that $v_1, \dots, v_m$ is linearly independent.
\end{exercise}
\begin{solution}
  Suppose $c_1, \dots, c_n \in \F$ are such that
  \[
    c_1 v_1 + \cdots + c_n v_n = 0.
  \]
  Applying $T$ to both sides of the equation above, we have
  \[
    c_1 Tv_1 + \cdots + c_n Tv_n = 0.
  \]
  Because $Tv_1, \dots, Tv_m$ is linearly independent, this implies that
  \[
    c_1 = \cdots = c_n = 0.
  \]
  Thus $v_1, \dots, v_m$ is linearly independent.
\end{solution}

\exerciseheader{3A}{5}
\begin{exercise}{5}
  Prove that $\mathcal{L}(V, W)$ is a vector space, as was asserted in~3.6.
\end{exercise}
\begin{solution}
  Suppose $S, T \in \mathcal{L}(V, W)$. Then
  \[
    (S + T)(v) = Sv + Tv = Tv + Sv = (T + S)v
  \]
  for every $v \in V$. Thus $S + T = T + S$. In other words, addition is commutative on $\mathcal{L}(V, W)$.

  Suppose $R, S, T \in \mathcal{L}(V, W)$. Then
  \begin{align*}
    ((R + S) + T)(v) &= (R + S)v + Tv \\
                     &= (Rv + Sv) + Tv \\
                     &= Rv + (Sv + Tv) \\
                     &= Rv + (S + T)v \\
                     &= (R + (S + T))(v)
  \end{align*}
  for every $v \in V$. Thus $(R + S) + T = R + (S + T)$. In other words, addition is associative on $\mathcal{L}(V, W)$.

  Suppose $a, b \in \F$ and $T \in \mathcal{L}(V, W)$. Then
  \begin{align*}
    ((ab)T)(v) &= (ab)(Tv) \\
               &= a(bTv) \\
               &= (a(bT))(v)
  \end{align*}
  for every $v \in V$. Thus $(ab)T = a(bT)$.

  The linear map $0 \in \mathcal{L}(V, W)$ defined by $0v = 0$ (where the $0$ on the right is the additive identity for $W$) is clearly an additive identity for $\mathcal{L}(V, W)$.

  For $T \in \mathcal{L}(V, W)$, define $-T \in \mathcal{L}(V, W)$ by
  \[
    (-T)(v) = -(Tv)
  \]
  for all $v \in V$. It is easy to verify that $-T$ is an additive inverse of $T$.

  Suppose $T \in \mathcal{L}(V, W)$. Then
  \[
    (1T)(v) = 1(Tv) = Tv
  \]
  for every $v \in V$. Thus $1T = T$.

  Suppose $a \in \F$ and $S, T \in \mathcal{L}(V, W)$. Then
  \begin{align*}
    (a(S + T))(v) &= a((S + T)(v)) \\
                  &= a(Sv + Tv) \\
                  &= a(Sv) + a(Tv) \\
                  &= (aS)(v) + (aT)(v) \\
                  &= (aS + aT)(v)
  \end{align*}
  for every $v \in V$. Thus $a(S + T) = aS + aT$.

  Suppose $a, b \in \F$ and $T \in \mathcal{L}(V, W)$. Then
  \begin{align*}
    ((a + b)T)(v) &= (a + b)(Tv) \\
                  &= a(Tv) + b(Tv) \\
                  &= (aT)(v) + (bT)(v) \\
                  &= (aT + bT)(v)
  \end{align*}
  for every $v \in V$. Thus $(a + b)T = aT + bT$.

  We have now verified that $\mathcal{L}(V, W)$ is a vector space with the operations of addition and scalar multiplication that were defined on $\mathcal{L}(V, W)$.
\end{solution}

\exerciseheader{3A}{6}
\begin{exercise}{6}
  Prove that multiplication of linear maps has the associative, identity, and distributive properties asserted in~3.8.
\end{exercise}
\begin{solution}
  Suppose $U, V, W, X$ are vector spaces over $\F$ and
  \[
    T_3 \in \mathcal{L}(U, V), \quad T_2 \in \mathcal{L}(V, W), \quad T_1 \in \mathcal{L}(W, X).
  \]
  Thus $(T_1 T_2)T_3$ and $T_1(T_2 T_3)$ are both elements of $\mathcal{L}(U, X)$.

  Now
  \begin{align*}
    ((T_1 T_2)T_3)(u) &= (T_1 T_2)(T_3 u) \\
                       &= T_1(T_2(T_3 u)) \\
                       &= T_1((T_2 T_3)(u)) \\
                       &= (T_1(T_2 T_3))(u)
  \end{align*}
  for every $u \in U$. Thus $(T_1 T_2)T_3 = T_1(T_2 T_3)$.

  Suppose $T \in \mathcal{L}(V, W)$. Then
  \[
    (TI)v = T(Iv) = Tv
  \]
  for every $v \in V$. Thus $TI = T$. Similarly,
  \[
    (IT)(v) = I(Tv) = Tv
  \]
  for every $v \in V$. Thus $IT = T$. Hence $TI = IT = T$.

  Suppose $U, V, W$ are vector spaces over $\F$. Suppose also that $T \in \mathcal{L}(U, V)$ and $S_1, S_2 \in \mathcal{L}(V, W)$. Then
  \begin{align*}
    ((S_1 + S_2)T)(u) &= (S_1 + S_2)(Tu) \\
                       &= S_1(Tu) + S_2(Tu) \\
                       &= (S_1 T)(u) + (S_2 T)(u) \\
                       &= (S_1 T + S_2 T)(u)
  \end{align*}
  for every $u \in U$. Thus $(S_1 + S_2)T = S_1 T + S_2 T$.

  Suppose $U, V, W$ are vector spaces over $\F$. Suppose also that $T_1, T_2 \in \mathcal{L}(U, V)$ and $S \in \mathcal{L}(V, W)$. Then
  \begin{align*}
    (S(T_1 + T_2))(u) &= S((T_1 + T_2)u) \\
                       &= S(T_1 u + T_2 u) \\
                       &= S(T_1 u) + S(T_2 u) \\
                       &= (ST_1)(u) + (ST_2)(u) \\
                       &= (ST_1 + ST_2)(u)
  \end{align*}
  for every $u \in U$. Thus $S(T_1 + T_2) = ST_1 + ST_2$.
\end{solution}

\exerciseheader{3A}{7}
\begin{exercise}{7}
  Show that every linear map from a one-dimensional vector space to itself is multiplication by some scalar. More precisely, prove that if $\dim V = 1$ and $T \in \mathcal{L}(V)$, then there exists $\lambda \in \F$ such that $Tv = \lambda v$ for all $v \in V$.
\end{exercise}
\begin{solution}
  Suppose $\dim V = 1$ and $T \in \mathcal{L}(V)$. Let $u$ be a nonzero vector in $V$. Then every vector in $V$ is a scalar multiple of $u$. In particular, $Tu = \lambda u$ for some $\lambda \in \F$.

  Now consider a typical vector $v \in V$. There exists $b \in \F$ such that $v = bu$. Thus
  \begin{align*}
    Tv &= T(bu) \\
       &= bT(u) \\
       &= b(\lambda u) \\
       &= \lambda(bu) \\
       &= \lambda v.
  \end{align*}
\end{solution}

\exerciseheader{3A}{8}
\begin{exercise}{8}
  Give an example of a function $\varphi\colon \R^2 \to \R$ such that
  \[
    \varphi(av) = a\varphi(v)
  \]
  for all $a \in \R$ and all $v \in \R^2$ but $\varphi$ is not linear.

  \textit{This exercise and the next exercise show that neither homogeneity nor additivity alone is enough to imply that a function is a linear map.}
\end{exercise}
\begin{solution}
  Define $\varphi\colon \R^2 \to \R$ by
  \[
    \varphi(x, y) = (x^3 + y^3)^{1/3}.
  \]
  Then $\varphi(av) = a\varphi(v)$ for all $a \in \R$ and all $v \in \R^2$. However, $\varphi$ is not linear, because $\varphi(1, 0) = 1$ and $\varphi(0, 1) = 1$ but
  \begin{align*}
    \varphi((1, 0) + (0, 1)) &= \varphi(1, 1) \\
                              &= 2^{1/3} \\
                              &\neq \varphi(1, 0) + \varphi(0, 1).
  \end{align*}

  Of course there are also many other examples.
\end{solution}
\begin{comment}
  This exercise shows that homogeneity alone is not enough to imply that a function is a linear map. Additivity alone is also not enough to imply that a function is a linear map, although the proof of this involves advanced tools that are beyond the scope of this book.
\end{comment}

\exerciseheader{3A}{9}
\begin{exercise}{9}
  Give an example of a function $\varphi\colon \C \to \C$ such that
  \[
    \varphi(w + z) = \varphi(w) + \varphi(z)
  \]
  for all $w, z \in \C$ but $\varphi$ is not linear. (Here $\C$ is thought of as a complex vector space.)

  \textit{There also exists a function $\varphi\colon \R \to \R$ such that $\varphi$ satisfies the additivity condition above but $\varphi$ is not linear. However, showing the existence of such a function involves considerably more advanced tools.}
\end{exercise}
\begin{solution}
  Define $\varphi\colon \C \to \C$ by
  \[
    \varphi(x + yi) = x - iy
  \]
  for all $x, y \in \R$. Then $\varphi$ is additive by $\varphi$ is not homogeneous with respect to complex scalars. For example,
  \[
    \varphi(ii) = \varphi(-1) = -1 \neq 1 = i(-i) = i\varphi(i)
  \]
  and thus $\varphi(ii) \neq i\varphi(i)$.
\end{solution}

\exerciseheader{3A}{10}
\begin{exercise}{10}
  Prove or give a counterexample: If $q \in \mathcal{P}(\R)$ and $T\colon \mathcal{P}(\R) \to \mathcal{P}(\R)$ is defined by $Tp = q \circ p$, then $T$ is a linear map.

  \textit{The function $T$ defined here differs from the function $T$ defined in the last bullet point of~3.3 by the order of the functions in the compositions.}
\end{exercise}
\begin{solution}
  To construct a counterexample, take $q(x) = x^2$, $p_1(x) = 1$, and $p_2(x) = x$. Then
  \[
    (Tp_1)(x) = 1 \quad \text{and} \quad (Tp_2)(x) = x^2
  \]
  for all $x \in \R$ but
  \[
    (T(p_1 + p_2))(x) = (1 + x)^2 = 1 + 2x + x^2.
  \]
  Thus $T(p_1 + p_2) \neq Tp_1 + Tp_2$, which implies that $T$ is not linear.
\end{solution}

\exerciseheader{3A}{11}
\begin{exercise}{11}
  Suppose $V$ is finite-dimensional and $T \in \mathcal{L}(V)$. Prove that $T$ is a scalar multiple of the identity if and only if $ST = TS$ for every $S \in \mathcal{L}(V)$.
\end{exercise}
\begin{solution}
  First $T = aI$ for some $a \in \F$. Let $S \in \mathcal{L}(V)$. Then
  \begin{align*}
    ST &= S(aI) \\
       &= aS \\
       &= (aI)S \\
       &= TS.
  \end{align*}

  To prove the implication in the other direction, suppose now that $ST = TS$ for all $S \in \mathcal{L}(V)$. We begin by proving that $v, Tv$ is linearly dependent for every $v \in V$. To do this, fix $v \in V$, and suppose $v, Tv$ is linearly independent. Then $v, Tv$ can be extended to a basis $v, Tv, u_1, \dots, u_n$ of $V$. Define $S \in \mathcal{L}(V)$ by
  \[
    S(av + bTv + c_1 u_1 + \cdots + c_n u_n) = bv.
  \]
  Thus $S(Tv) = v$ and $Sv = 0$. Thus the equation $S(Tv) = T(Sv)$ becomes the equation $v = 0$, a contradiction because $v, Tv$ was assumed to be linearly independent. This contradiction shows that $v, Tv$ is linearly dependent for every $v \in V$. This implies that for each $v \in V \setminus \{0\}$, there exists $a_v \in \F$ such that
  \[
    Tv = a_v v.
  \]

  To show that $T$ is a scalar multiple of the identity, we must show that $a_v$ is independent of $v$. To do this, suppose $v, w \in V \setminus \{0\}$. We want to show that $a_v = a_w$. First consider the case where $v, w$ is linearly dependent. Then there exists $b \in \F$ such that $w = bv$. We have
  \begin{align*}
    a_w w &= Tw \\
           &= T(bv) \\
           &= bTv \\
           &= b(a_v v) \\
           &= a_v(bv) \\
           &= a_v w,
  \end{align*}
  which shows that $a_v = a_w$, as desired.

  Finally, consider the case where $v, w$ is linearly independent. We have
  \begin{align*}
    a_{v+w}(v + w) &= T(v + w) \\
                    &= Tv + Tw \\
                    &= a_v v + a_w w,
  \end{align*}
  which implies that
  \[
    (a_{v+w} - a_v)v + (a_{v+w} - a_w)w = 0.
  \]
  Because $v, w$ is linearly independent, this implies that $a_{v+w} = a_v$ and $a_{v+w} = a_w$, so again we have $a_v = a_w$, as desired.
\end{solution}

\exerciseheader{3A}{12}
\begin{exercise}{12}
  Suppose $U$ is a subspace of $V$ with $U \neq V$. Suppose $S \in \mathcal{L}(U, W)$ and $S \neq 0$ (which means $Su \neq 0$ for some $u \in U$). Define $T\colon V \to W$ by
  \[
    Tv = \begin{cases}
      Sv & \text{if } v \in U, \\
      0  & \text{if } v \in V \text{ and } v \notin U.
    \end{cases}
  \]
  Prove that $T$ is not a linear map on $V$.
\end{exercise}
\begin{solution}
  Let $u \in U$ be such that $Su \neq 0$. Let $w \in V$ be such that $w \notin U$. Then $u + w \notin U$ [because $u + w \in U$ would imply that $(u + w) + (-u)$, which equals $w$, is in $U$]. Thus
  \[
    T(u + w) = 0.
  \]
  However,
  \[
    Tu + Tw = Tu + 0 = Tu = Su \neq 0.
  \]
  Thus $T(u + w) \neq Tu + Tw$. Hence $T$ is not linear.
\end{solution}

\exerciseheader{3A}{13}
\begin{exercise}{13}
  Suppose $V$ is finite-dimensional. Prove that every linear map on a subspace of $V$ can be extended to a linear map on $V$. In other words, show that if $U$ is a subspace of $V$ and $S \in \mathcal{L}(U, W)$, then there exists $T \in \mathcal{L}(V, W)$ such that $Tu = Su$ for all $u \in U$.

  \textit{The result in this exercise is used in the proof of~3.125.}
\end{exercise}
\begin{solution}
  Suppose $U$ is a subspace of $V$ and $S \in \mathcal{L}(U, W)$. Choose a basis $u_1, \dots, u_m$ of $U$. Then $u_1, \dots, u_m$ is a linearly independent list of vectors in $V$, and so can be extended to a basis $u_1, \dots, u_m, v_1, \dots, v_n$ of $V$ (by 2.32). Define $T \in \mathcal{L}(V, W)$ by
  \[
    T(a_1 u_1 + \dots a_m u_m + b_1 v_1 + \cdots + b_n v_n) = a_1 Su_1 + \cdots + a_m Su_m.
  \]
  Then $Tu = Su$ for all $u \in U$.
\end{solution}

\exerciseheader{3A}{14}
\begin{exercise}{14}
  Suppose $V$ is finite-dimensional with $\dim V > 0$, and suppose $W$ is infinite-dimensional. Prove that $\mathcal{L}(V, W)$ is infinite-dimensional.
\end{exercise}
\begin{solution}
  Suppose $W$ is infinite-dimensional. Let $v_1, \dots, v_m$ be a basis of $V$.

  Because $W$ is infinite-dimensional, there exists a sequence $w_1, w_2, \dots$ such that $w_1, \dots, w_n$ is linearly independent for each positive integer $n$.

  For each positive integer $n$, use the linear map lemma (3.4) to define a linear map $T_n \in \mathcal{L}(V, W)$ such that
  \[
    T_n(v_k) = w_n
  \]
  for all $k = 1, \dots, m$.

  Suppose $n$ is a positive integer and $c_1, \dots, c_n \in \F$ are such that
  \[
    c_1 T_1 + \cdots + c_n T_n = 0.
  \]
  Applying both sides of the equation above to the vector $v_1$ gives
  \[
    c_1 w_1 + \cdots + c_n w_n = 0.
  \]
  Because $w_1, \dots, w_n$ is linearly independent, the equation above implies that $c_1 = \cdots = c_n = 0$. Thus $T_1, \dots, T_n$ is a linearly independent list in $\mathcal{L}(V, W)$.

  Because $\mathcal{L}(V, W)$ has a linearly independent list of length $n$ for every positive integer $n$, we conclude that $\mathcal{L}(V, W)$ is infinite-dimensional.
\end{solution}

\exerciseheader{3A}{15}
\begin{exercise}{15}
  Suppose $v_1, \dots, v_m$ is a linearly dependent list of vectors in $V$. Suppose also that $W \neq \{0\}$. Prove that there exist $w_1, \dots, w_m \in W$ such that no $T \in \mathcal{L}(V, W)$ satisfies $Tv_k = w_k$ for each $k = 1, \dots, m$.
\end{exercise}
\begin{solution}
  If $v_1 = 0$, let $w_1$ be a nonzero vector in $W$. Then there does not exist a linear map $T \in \mathcal{L}(V, W)$ such that $Tv_1 = w_1$ (by 3.10).

  If $v_1 \neq 0$, then by the linear dependence lemma (2.19) there exists $j \in \{2, \dots, m\}$ and $c_1, \dots, c_{j-1} \in \F$ such that
  \[
    v_j = c_1 v_1 + \cdots + c_{j-1} v_{j-1}.
  \]
  Let $w_k = 0$ for all $k = 1, \dots, j - 1$ and let $w_j$ equal any nonzero vector in $W$. Then the equation above and 3.10 imply that there does not exist a linear map $T \in \mathcal{L}(V, W)$ such that $Tv_k = w_k$ for all $k = 1, \dots, j$.
\end{solution}

\exerciseheader{3A}{16}
\begin{exercise}{16}
  Suppose $V$ is finite-dimensional with $\dim V > 1$. Prove that there exist $S, T \in \mathcal{L}(V)$ such that $ST \neq TS$.
\end{exercise}
\begin{solution}
  Let $v_1, \dots, v_n$ be a basis of $V$. Use the linear map lemma (3.4) to define $S, T \in \mathcal{L}(V)$ such that
  \[
    Sv_k = \begin{cases}
      v_2 & \text{if } k = 1, \\
      0   & \text{if } k \neq 1,
    \end{cases}
    \quad \text{and} \quad
    Tv_k = \begin{cases}
      v_1 & \text{if } k = 2, \\
      0   & \text{if } k \neq 2.
    \end{cases}
  \]
  Then
  \[
    (ST)(v_1) = S(Tv_1) = S0 = 0
  \]
  but
  \[
    (TS)(v_1) = T(Sv_1) = Tv_2 = v_1.
  \]
  Thus $ST \neq TS$.
\end{solution}

\exerciseheader{3A}{17}
\begin{exercise}{17}
  Suppose $V$ is finite-dimensional. Show that the only two-sided ideals of $\mathcal{L}(V)$ are $\{0\}$ and $\mathcal{L}(V)$.

  \textit{A subspace $\mathcal{E}$ of $\mathcal{L}(V)$ is called a \textbf{two-sided ideal} of $\mathcal{L}(V)$ if $TE \in \mathcal{E}$ and $ET \in \mathcal{E}$ for all $E \in \mathcal{E}$ and all $T \in \mathcal{L}(V)$.}
\end{exercise}
\begin{solution}
  Suppose $\mathcal{E}$ is a two-sided ideal of $\mathcal{L}(V)$ and $\mathcal{E} \neq \{0\}$. We will prove that $\mathcal{E} = \mathcal{L}(V)$.

  Let $T \in \mathcal{E}$ be such that $T \neq 0$. Let $w \in V$ be such that $Tw \neq 0$. Let $v_1, \dots, v_n$ be a basis of $V$ (thus $n = \dim V$).

  For $1 \leq k \leq n$, let $S_k \in \mathcal{L}(V)$ be the linear map (whose existence is guaranteed by the linear map lemma 3.4) such that
  \[
    S_k v_j = \begin{cases}
      w & \text{if } j = k, \\
      0 & \text{if } j \neq k.
    \end{cases}
  \]
  Because $Tw \neq 0$, the list $Tw$ of length one can be extended to a basis of $V$. Thus for each $1 \leq k \leq n$, there exists $R_k \in \mathcal{L}(V)$ such that
  \[
    R_k(Tw) = v_k,
  \]
  where again we have used the linear map lemma (3.4).

  Now for each $1 \leq k \leq n$, we have
  \[
    R_k T S_k v_j = \begin{cases}
      v_j & \text{if } j = k, \\
      0   & \text{if } j \neq k.
    \end{cases}
  \]
  Hence
  \[
    \Bigl(\sum_{k=1}^{n} R_k T S_k\Bigr) v_j = v_j.
  \]
  for every $j = 1, \dots, n$. This implies that
  \[
    \sum_{k=1}^{n} R_k T S_k = I,
  \]
  where $I$ is the identity operator on $V$.

  Because $\mathcal{E}$ is a two-sided ideal of $\mathcal{L}(V)$, each $R_k T S_k \in \mathcal{E}$. Thus the equation above implies that $I \in \mathcal{E}$.

  If $T \in \mathcal{L}(V)$ then $TI = T$ and hence $T \in \mathcal{L}(V)$ [because $I \in \mathcal{E}$ and $\mathcal{E}$ is a two-sided ideal of $\mathcal{L}(V)$]. Hence we conclude that $\mathcal{E} = \mathcal{L}(V)$, as desired.
\end{solution}
